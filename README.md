# Image Captioning Project

This project generates captions for images using a deep learning model.

 Project Structure:
- train.py â€” training script
- inference.py â€” run the model for predictions
- utils/ â€” helper functions and datasets
- sample.jpg â€” sample image
- vocab.pkl â€” vocabulary file
- build_vocab.py` â€” Builds vocabulary from captions dataset  
- caption_model.py â€” Defines the image captioning model  
- check_model.py â€” Checks if the model loads correctly  
- check_vocab_size.py â€” Verifies vocabulary size  
- copy_subset_images.py â€” Copies a subset of images  
- create_clean_subset.py â€” Cleans and prepares dataset  
- create_subset.py â€” Creates a smaller dataset subset  
- inference.py â€” Generates captions for images  
- model.py â€” Model helper functions  
- streamlit_app.py â€” Web app for generating captions  
- train.py â€” Trains the image captioning model

## How to Run
1. Install dependencies: pip install -r requirements.txt
2. Run Train: python train.py
3. Run inference: python inference.py
4. For Output: streamlit run streamlit_app.py

ğŸ› ï¸ Technologies Used

Here are the main technologies and tools I used to build this Image Captioning project:

ğŸ Python â€“ Core programming language

ğŸ”¥ PyTorch â€“ For building and training the deep learning model

ğŸ§  CNN (ResNet / VGG) â€“ Used for extracting image features

âœï¸ RNN / LSTM â€“ Used for generating captions word by word

ğŸ‹ï¸ TorchVision â€“ For loading pretrained image models

ğŸ”¡ NLTK / Text Processing â€“ Used for cleaning text and creating vocabulary

ğŸ“¦ Pickle (pkl) â€“ For saving the vocabulary

ğŸ–¼ï¸ PIL / OpenCV â€“ For handling and preprocessing images

ğŸ“Š Matplotlib â€“ For visualizing samples (optional)

ğŸŒ Streamlit â€“ For creating a simple web app to test the model

ğŸ—‚ï¸ COCO / Flickr8k Dataset â€“ Dataset used for training captions

ğŸ§° NumPy & Pandas â€“ For data handling and processing

